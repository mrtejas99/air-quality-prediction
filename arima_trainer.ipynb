{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6T01yH6Vj7uw"
      },
      "outputs": [],
      "source": [
        "# grid search ARIMA parameters for time series\n",
        "import warnings\n",
        "from math import sqrt\n",
        "from pandas import read_csv\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8lTbIwwkB55"
      },
      "outputs": [],
      "source": [
        "# evaluate an ARIMA model for a given order (p,d,q)\n",
        "def evaluate_arima_model(X, arima_order):\n",
        "\t# prepare training dataset\n",
        "\ttrain_size = int(len(X) * 0.66)\n",
        "\ttrain, test = X[0:train_size], X[train_size:]\n",
        "\thistory = [x for x in train]\n",
        "\t# make predictions\n",
        "\tpredictions = list()\n",
        "\tfor t in range(len(test)):\n",
        "\t\tmodel = ARIMA(history, order=arima_order)\n",
        "\t\tmodel_fit = model.fit()\n",
        "\t\tyhat = model_fit.forecast()[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\thistory.append(test[t])\n",
        "\t# calculate out of sample error\n",
        "\trmse = sqrt(mean_squared_error(test, predictions))\n",
        "\treturn rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EcKVJ6EkHO2"
      },
      "outputs": [],
      "source": [
        "# evaluate combinations of p, d and q values for an ARIMA model\n",
        "def evaluate_models(dataset, p_values, d_values, q_values):\n",
        "\tf = open(\"arima_metrics.txt\", \"a\")\n",
        "\tdataset = dataset.astype('float32')\n",
        "\tbest_score, best_cfg = float(\"inf\"), None\n",
        "\tfor p in p_values:\n",
        "\t\tfor d in d_values:\n",
        "\t\t\tfor q in q_values:\n",
        "\t\t\t\torder = (p,d,q)\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\trmse = evaluate_arima_model(dataset, order)\n",
        "\t\t\t\t\tprint('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
        "\t\t\t\t\tf.write(order + ' ' + rmse+\"\\n\")\n",
        "\t\t\t\t\tif rmse < best_score:\n",
        "\t\t\t\t\t\tbest_score, best_cfg = rmse, order\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\tf.close()\n",
        "\tprint('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_Y2GhC8kNhj"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "series = read_csv('clean_data.csv', usecols=[0,5], index_col=0, parse_dates=True)\n",
        "# evaluate parameters\n",
        "p_values = [0, 1, 2, 4, 6, 8, 10]\n",
        "d_values = range(0, 3)\n",
        "q_values = range(0, 3)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "metrics = evaluate_models(series.values, p_values, d_values, q_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIVPM3F2tjBa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
